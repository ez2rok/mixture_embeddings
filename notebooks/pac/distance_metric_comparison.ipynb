{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance metric comparison\n",
    "> Do the pairwise distances between mixture embeddings correlate with things like beta-diversity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clustering must allow custom distance metric\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from skbio import TreeNode\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio.diversity.beta import unweighted_unifrac, weighted_unifrac\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from geomstats.geometry.hyperbolic import Hyperbolic\n",
    "\n",
    "from util import mixture_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For UniFrac:\n",
    "# Load tree; iterate through all branches and print length; fix if None\n",
    "tree = TreeNode.read(\n",
    "    \"/home/phil/DATA/greengenes/data/gg_13_5_otus_99_annotated.tree\"\n",
    ")\n",
    "for i in tree.postorder(include_self=False):\n",
    "    if i.length is None:\n",
    "        print(i.name, i.length)\n",
    "        i.length = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:42<00:00,  8.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Head 20 = ~19 minutes for the whole thing\n",
    "# Head 50 = ~2 hours\n",
    "# Running this on the full table takes a long time, approx. 2 hours\n",
    "\n",
    "# OK, that was too slow. Let's do dists separately for each study:\n",
    "def get_dists(dist_function, embed=None, head=10, **kwargs):\n",
    "    dists = []\n",
    "    dir = \"/home/phil/mixture_embeddings/data/interim/mlrepo_clean/classification\"\n",
    "    for subdir in tqdm(os.listdir(dir)):\n",
    "        path = os.path.join(dir, subdir, \"otus.txt\")\n",
    "        if os.path.exists(path):\n",
    "            otu_table = pd.read_table(path, dtype={0: str})\n",
    "            \n",
    "            otu_table = otu_table.set_index(\n",
    "                otu_table.columns[0]\n",
    "            ).astype(float).T\n",
    "\n",
    "            if head is not None:\n",
    "                otu_table = otu_table.head(head)\n",
    "\n",
    "            if dist_function == \"unifrac\":\n",
    "                sample_dists = pdist(\n",
    "                    otu_table, \n",
    "                    metric=unweighted_unifrac, \n",
    "                    otu_ids=otu_table.columns, \n",
    "                    tree=tree.shear(otu_table.columns) # Shearing is faster\n",
    "                )\n",
    "            else:\n",
    "                sample_dists = pdist(otu_table, metric=dist_function, **kwargs)\n",
    "            dists.append(sample_dists)\n",
    "    \n",
    "    # return np.array([x.data.flatten() for x in dists])\n",
    "    return np.concatenate(dists)\n",
    "\n",
    "# unifrac_dists = get_dists(\"unifrac\")\n",
    "unifrac_dists = get_dists(\"unifrac\", head=HEAD)\n",
    "\n",
    "# Takes more than 20 minutes to run on first OTU table...\n",
    "np.save(f\"data/processed/distances/unifrac_dists_top{HEAD}.npy\", unifrac_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 14.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Beta diversity\n",
    "dists = []\n",
    "dir = \"/home/phil/mixture_embeddings/data/interim/mlrepo_clean/classification\"\n",
    "for subdir in tqdm(os.listdir(dir)):\n",
    "    path = os.path.join(dir, subdir, \"otus.txt\")\n",
    "    if os.path.exists(path):\n",
    "        otu_table = pd.read_table(path, dtype={0: str})\n",
    "        \n",
    "        otu_table = otu_table.set_index(\n",
    "            otu_table.columns[0]\n",
    "        ).astype(float).T\n",
    "\n",
    "        otu_table = otu_table.head(HEAD)\n",
    "\n",
    "        sample_dists = beta_diversity(counts=otu_table, metric=\"braycurtis\")\n",
    "        dists.append(sample_dists)\n",
    "    \n",
    "beta_diversity_dists = np.array([x.data.flatten() for x in dists])\n",
    "\n",
    "np.save(f\"data/processed/distances/beta_diversity_dists_top{HEAD}.npy\", beta_diversity_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]WARNING: Maximum number of iterations 1000 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 1000 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 1000 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 1000 reached. The mean may be inaccurate\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.04it/s]\n",
      "  0%|          | 0/19 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A 2-dimensional array must be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     25\u001b[0m         otu_table_euc \u001b[39m=\u001b[39m mixture_embedding(\n\u001b[1;32m     26\u001b[0m             otu_table,\n\u001b[1;32m     27\u001b[0m             geometry\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m             otu_embeddings\u001b[39m=\u001b[39meuc_embeddings\n\u001b[1;32m     29\u001b[0m         )\n\u001b[1;32m     31\u001b[0m         otu_table_hyp \u001b[39m=\u001b[39m mixture_embedding(\n\u001b[1;32m     32\u001b[0m             otu_table,\n\u001b[1;32m     33\u001b[0m             geometry\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhyperbolic\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m             otu_embeddings\u001b[39m=\u001b[39mhyp_embeddings\n\u001b[1;32m     35\u001b[0m         )\n\u001b[0;32m---> 37\u001b[0m         euc_dists\u001b[39m.\u001b[39mappend(pdist(sample_dists, metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     38\u001b[0m         hyp_dists\u001b[39m.\u001b[39mappend(pdist(sample_dists, metric\u001b[39m=\u001b[39mhyp_manifold\u001b[39m.\u001b[39m_metric\u001b[39m.\u001b[39mdist))\n\u001b[1;32m     40\u001b[0m euc_dists \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x\u001b[39m.\u001b[39mflatten() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m euc_dists])\n",
      "File \u001b[0;32m~/mambaforge/envs/americangut/lib/python3.11/site-packages/scipy/spatial/distance.py:2200\u001b[0m, in \u001b[0;36mpdist\u001b[0;34m(X, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m s \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m   2199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 2200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA 2-dimensional array must be passed.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2202\u001b[0m m, n \u001b[39m=\u001b[39m s\n\u001b[1;32m   2204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(metric):\n",
      "\u001b[0;31mValueError\u001b[0m: A 2-dimensional array must be passed."
     ]
    }
   ],
   "source": [
    "for size in [2, 4, 8, 16, 32, 64, 128]:\n",
    "    # Get embedding distance matrices\n",
    "    euc_embeddings = pd.read_csv(f\"/home/phil/DATA/otu_embeddings/embeddings_euclidean_{size}.csv\", dtype={0: str})\n",
    "    euc_embeddings = euc_embeddings.set_index(euc_embeddings.columns[0])\n",
    "\n",
    "    hyp_embeddings = pd.read_csv(f\"/home/phil/DATA/otu_embeddings/embeddings_hyperbolic_{size}.csv\", dtype={0: str})\n",
    "    hyp_embeddings = hyp_embeddings.set_index(hyp_embeddings.columns[0])\n",
    "\n",
    "    hyp_manifold = Hyperbolic(size, default_coords_type=\"ball\")\n",
    "\n",
    "    euc_dists = []\n",
    "    hyp_dists = []\n",
    "    dir = \"/home/phil/mixture_embeddings/data/interim/mlrepo_clean/classification\"\n",
    "    for subdir in tqdm(os.listdir(dir)):\n",
    "        path = os.path.join(dir, subdir, \"otus.txt\")\n",
    "        if os.path.exists(path):\n",
    "            otu_table = pd.read_table(path, dtype={0: str})\n",
    "            \n",
    "            otu_table = otu_table.set_index(\n",
    "                otu_table.columns[0]\n",
    "            ).astype(float).T\n",
    "\n",
    "            otu_table = otu_table.head(HEAD)\n",
    "\n",
    "            otu_table_euc = mixture_embedding(\n",
    "                otu_table,\n",
    "                geometry=\"euclidean\",\n",
    "                otu_embeddings=euc_embeddings\n",
    "            )\n",
    "\n",
    "            otu_table_hyp = mixture_embedding(\n",
    "                otu_table,\n",
    "                geometry=\"hyperbolic\",\n",
    "                otu_embeddings=hyp_embeddings\n",
    "            )\n",
    "\n",
    "            euc_dists.append(pdist(sample_dists, metric=\"euclidean\"))\n",
    "            hyp_dists.append(pdist(sample_dists, metric=hyp_manifold._metric.dist))\n",
    "    \n",
    "    euc_dists = np.array([x.flatten() for x in euc_dists])\n",
    "    hyp_dists = np.array([x.flatten() for x in hyp_dists])\n",
    "\n",
    "    np.save(f\"data/processed/distances/euc_dists_top{HEAD}_{size}.npy\", euc_dists)\n",
    "    np.save(f\"data/processed/distances/euc_dists_top{HEAD}_{size}.npy\", hyp_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dists\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4dc294415b14ea4c0d4d07894c031d87e01c25f832e475b95612eada6e667d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
