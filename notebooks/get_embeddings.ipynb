{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from geomstats.geometry.hyperbolic import Hyperbolic\n",
    "from geomstats.learning.frechet_mean import FrechetMean\n",
    "\n",
    "# local files\n",
    "from src.util.data_handling.string_generator import str_seq_to_num_seq, ALPHABETS\n",
    "from src.util.data_handling.data_loader import save_as_pickle, load_dataset, make_dir\n",
    "from src.util.data_handling.closest_string_dataset import ReferenceDataset, QueryDataset\n",
    "\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_stack():\n",
    "    \"\"\"Source: https://stackoverflow.com/a/16589622/14773537.\"\"\"\n",
    "    import traceback, sys\n",
    "    exc = sys.exc_info()[0]\n",
    "    stack = traceback.extract_stack()[:-1]  # last one would be full_stack()\n",
    "    if exc is not None:  # i.e. an exception is present\n",
    "        del stack[-1]       # remove call of full_stack, the printed exception\n",
    "                            # will contain the caught exception caller instead\n",
    "    trc = 'Traceback (most recent call last):\\n'\n",
    "    stackstr = trc + ''.join(traceback.format_list(stack))\n",
    "    if exc is not None:\n",
    "         stackstr += '  ' + traceback.format_exc().lstrip(trc)\n",
    "    return stackstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(encoder_path):\n",
    "    \n",
    "    # model\n",
    "    encoder_model, state_dict = torch.load(encoder_path)\n",
    "    encoder_model.load_state_dict(state_dict)\n",
    "\n",
    "    # Restore best model\n",
    "    print('Loading model ' + encoder_path)\n",
    "    encoder_model.load_state_dict(state_dict)\n",
    "    encoder_model.eval()\n",
    "    \n",
    "    return encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_seq(ids, auxillary_data_path):\n",
    "    \n",
    "    id_to_str_seq, _, alphabet_str, length = load_dataset(auxillary_data_path)\n",
    "    alphabet = ALPHABETS[alphabet_str]\n",
    "    str_seqs = [id_to_str_seq[str(_id)] for _id in ids]\n",
    "    num_seqs = [str_seq_to_num_seq(s, length=length, alphabet=alphabet) for s in tqdm(str_seqs, desc='Convert string sequences to numerical sequences')]\n",
    "    return num_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(num_seq, batch_size, labels=None):\n",
    "    \"\"\"Convert a num_seq to a dataloader. Optionally can add labels too.\"\"\"\n",
    "    \n",
    "    if labels is  None:\n",
    "        dataset = ReferenceDataset(num_seq) # iterate over just num_seq\n",
    "    else:\n",
    "        dataset = QueryDataset(num_seq, labels) # iterate over num_seq and labels together\n",
    "        \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_strings(loader, model, device, desc='Embedding sequences'):\n",
    "    \"\"\" Embeds the sequences of a dataset one batch at the time given an encoder \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for sequences in tqdm(loader, desc=desc):\n",
    "        if isinstance(sequences, list): # query dataloader iterates over (sequences, label); so here sequnces is a list and must remove label\n",
    "            sequences = sequences[0]\n",
    "        sequences = sequences.to(device)\n",
    "        embedded = model.encode(sequences)\n",
    "        embeddings.append(embedded.cpu().detach())\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_otu_embeddings(data, encoder_path, batch_size, seed=42, no_cuda=False, labels=None, auxillary_data_path=None):\n",
    "    \"\"\"Compute otu embeddings.\n",
    "    \n",
    "    Data can either be a list of ids or num_seq.\n",
    "    * If it is a list of ids, then we will need auxillary_data_path and will\n",
    "      automatically compute num_seq from the data and then get the embeddings.\n",
    "    * Otherwise if data is num_seq to begin with we will just simply get the\n",
    "      embeddings.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # set device\n",
    "    cuda = not no_cuda and torch.cuda.is_available()\n",
    "    device = 'cuda' if cuda else 'cpu'\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # set random seed\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "    # load model\n",
    "    encoder_model = load_model(encoder_path)\n",
    "    \n",
    "    # load data\n",
    "    if auxillary_data_path is not None:\n",
    "        ids = data\n",
    "        num_seq = get_num_seq(ids, auxillary_data_path)\n",
    "    else:\n",
    "        num_seq = data\n",
    "        \n",
    "    # get dataloader\n",
    "    loader = get_dataloader(num_seq, batch_size, labels)\n",
    "    \n",
    "    # embed strings\n",
    "    embeddings = embed_strings(loader, encoder_model, device)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mixture_embeddings(data, otu_embeddings, distance_str):\n",
    "    \"\"\"Compute mixture embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas DataFrame of shape (n_samples, n_otus)\n",
    "        Dataframe where the ijth entry is how much the ith person has of the jth\n",
    "       otu.\n",
    "    otu_embeddings : np.ndarray of shape (n_otus, embedding_size)\n",
    "        _description_\n",
    "    distance_str : string\n",
    "        The distance metric used to generate the otu_embeddings. distance_str\n",
    "        should be `hyperbolic` or euclidean`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mixture_embeddings : np.ndarray of shape (n_samples, embedding_size)\n",
    "        The mixture embeddings of each sample weighted by the otu abudances of\n",
    "        that sample.\n",
    "    \"\"\"\n",
    "        \n",
    "    # initialize values\n",
    "    weights = data.to_numpy()\n",
    "    mixture_embeddings = []\n",
    "    n_errors = 0\n",
    "    \n",
    "    # initialize frechet mean\n",
    "    embedding_size = otu_embeddings.shape[1]\n",
    "    hyperbolic = Hyperbolic(dim=embedding_size, default_coords_type='ball')\n",
    "    fmean = FrechetMean(hyperbolic.metric, max_iter=1000, method='adaptive')\n",
    "        \n",
    "    for i in tqdm(range(len(data)), desc='Mixture Embeddings', disable=True):\n",
    "        \n",
    "        # compute the mixtured embedding for the current sample\n",
    "        # temporarily set warnings to errors so can identify when Frechet mean does not converge\n",
    "        # Source: https://stackoverflow.com/a/30368735/14773537\n",
    "        if distance_str == 'hyperbolic':\n",
    "            \n",
    "            warnings.filterwarnings(\"error\") # treat warnings like errors\n",
    "            try:\n",
    "                mixture_embedding = fmean.fit(otu_embeddings, weights=weights[i]).estimate_  \n",
    "            except Exception as error:\n",
    "                # ic(i, error)\n",
    "                # print(full_stack())\n",
    "                mixture_embedding = np.zeros(embedding_size)\n",
    "                n_errors += 1\n",
    "            warnings.resetwarnings() # treat warnings like warnings again\n",
    "            # return\n",
    "\n",
    "        else:\n",
    "            mixture_embedding = np.average(otu_embeddings, weights=weights[i], axis=0)\n",
    "        mixture_embeddings.append(mixture_embedding)\n",
    "        \n",
    "    ic(n_errors)\n",
    "    mixture_embeddings = np.array(mixture_embeddings)\n",
    "    return mixture_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(encoder_path, ihmp_data_path, outdir, batch_size, auxillary_data_path='data/interim/greengenes/auxillary_data.pickle', seed=42, save=True, no_cuda=False):\n",
    "    \"\"\"Get mixture embeddings for all data\"\"\"\n",
    "    \n",
    "    # inital values\n",
    "    model_name = '_'.join(encoder_path.split('/')[-1].split('_')[:-1])\n",
    "    distance_str = model_name.split('_')[1]\n",
    "    data_name = ihmp_data_path.split('/')[-1].split(\"_\")[0]\n",
    "    print('\\n' + '-'*5 + 'Compute {} Embeddings'.format(data_name) + '-'*5)\n",
    "    \n",
    "    # load data        \n",
    "    data = pd.read_csv(ihmp_data_path, index_col='Sample')\n",
    "    otu_ids = data.columns.to_list()\n",
    "\n",
    "    # compute and save otu embeddings\n",
    "    otu_embeddings = get_otu_embeddings(otu_ids, encoder_path, batch_size, seed=seed, no_cuda=no_cuda, auxillary_data_path=auxillary_data_path)\n",
    "    otu_embeddings_df = pd.DataFrame(otu_embeddings, index=data.columns)\n",
    "    otu_embeddings_df.index.name = 'OTU'\n",
    "    if save:\n",
    "        otu_filename = '{}/otu_embeddings/{}/{}_otu_embeddings.csv'.format(outdir, data_name, model_name)\n",
    "        otu_embeddings_df.to_csv(make_dir(otu_filename))\n",
    "    \n",
    "    # compute and save mixture embeddings\n",
    "    mixture_embeddings = get_mixture_embeddings(data, otu_embeddings, distance_str)\n",
    "    mixture_embeddings_df = pd.DataFrame(mixture_embeddings, index=data.index.to_list())\n",
    "    mixture_embeddings_df.index.name = 'Sample'\n",
    "    if save:\n",
    "        mixture_filename = '{}/mixture_embeddings/{}/{}_mixture_embeddings.csv'.format(outdir, data_name, model_name)\n",
    "        mixture_embeddings_df.to_csv(make_dir(mixture_filename))\n",
    "    \n",
    "    return otu_embeddings_df, mixture_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Compute ibd Embeddings-----\n",
      "Using device: cuda\n",
      "Loading model ../models/cnn_hyperbolic_2_model.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert string sequences to numerical sequences: 100%|██████████| 1370/1370 [00:00<00:00, 3519.46it/s]\n",
      "Embedding sequences: 100%|██████████| 11/11 [00:01<00:00,  6.06it/s]\n",
      "WARNING: Maximum number of iterations 1000 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 1000 reached. The mean may be inaccurate\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: BackendImporter.find_spec() not found; falling back to find_module()\n",
      "ic| n_errors: 19\n"
     ]
    }
   ],
   "source": [
    "data_name = 'ibd'\n",
    "distance = 'hyperbolic'\n",
    "embedding_size = 2\n",
    "batch_size = 128\n",
    "no_cuda = False\n",
    "save = True\n",
    "\n",
    "encoder_path = '../models/cnn_{}_{}_model.pickle'.format(distance, embedding_size)\n",
    "ihmp_data_path = '../data/interim/ihmp/{}_data.csv'.format(data_name)\n",
    "outdir = '../data/processed'\n",
    "auxillary_data_path = '../data/interim/greengenes/auxillary_data.pickle'\n",
    "\n",
    "\n",
    "otu_embeddings_df, mixture_embeddings_df = get_embeddings(\n",
    "    encoder_path, \n",
    "    ihmp_data_path,\n",
    "    outdir,\n",
    "    batch_size,\n",
    "    auxillary_data_path=auxillary_data_path,\n",
    "    save=save\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTU</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000269</th>\n",
       "      <td>-0.971315</td>\n",
       "      <td>-0.233556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008348</th>\n",
       "      <td>-0.188370</td>\n",
       "      <td>0.981080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009894</th>\n",
       "      <td>-0.938192</td>\n",
       "      <td>0.343216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012376</th>\n",
       "      <td>-0.713432</td>\n",
       "      <td>0.699297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017181</th>\n",
       "      <td>-0.995324</td>\n",
       "      <td>-0.085623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976470</th>\n",
       "      <td>-0.775837</td>\n",
       "      <td>-0.629347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979707</th>\n",
       "      <td>-0.535303</td>\n",
       "      <td>0.843476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988375</th>\n",
       "      <td>-0.504512</td>\n",
       "      <td>0.862246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988932</th>\n",
       "      <td>-0.979092</td>\n",
       "      <td>-0.198445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999046</th>\n",
       "      <td>-0.993065</td>\n",
       "      <td>0.108737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1\n",
       "OTU                        \n",
       "1000269 -0.971315 -0.233556\n",
       "1008348 -0.188370  0.981080\n",
       "1009894 -0.938192  0.343216\n",
       "1012376 -0.713432  0.699297\n",
       "1017181 -0.995324 -0.085623\n",
       "...           ...       ...\n",
       "976470  -0.775837 -0.629347\n",
       "979707  -0.535303  0.843476\n",
       "988375  -0.504512  0.862246\n",
       "988932  -0.979092 -0.198445\n",
       "999046  -0.993065  0.108737\n",
       "\n",
       "[1370 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otu_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CSM5FZ3N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSM5FZ3X</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSM5FZ3Z</th>\n",
       "      <td>-0.019282</td>\n",
       "      <td>0.780946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSM5FZ44</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSM5FZ46</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSM5LLIO</th>\n",
       "      <td>-0.187492</td>\n",
       "      <td>0.394580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSM5LLIQ</th>\n",
       "      <td>-0.359186</td>\n",
       "      <td>0.083998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSM5LLIS</th>\n",
       "      <td>-0.237867</td>\n",
       "      <td>0.063742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSM5ZOJY</th>\n",
       "      <td>-0.379982</td>\n",
       "      <td>-0.431924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSM633FF</th>\n",
       "      <td>-0.137279</td>\n",
       "      <td>0.233639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "Sample                      \n",
       "CSM5FZ3N  0.000000  0.000000\n",
       "CSM5FZ3X  0.000000  0.000000\n",
       "CSM5FZ3Z -0.019282  0.780946\n",
       "CSM5FZ44  0.000000  0.000000\n",
       "CSM5FZ46  0.000000  0.000000\n",
       "...            ...       ...\n",
       "MSM5LLIO -0.187492  0.394580\n",
       "MSM5LLIQ -0.359186  0.083998\n",
       "MSM5LLIS -0.237867  0.063742\n",
       "MSM5ZOJY -0.379982 -0.431924\n",
       "MSM633FF -0.137279  0.233639\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture_embeddings_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "\n",
    "IBD Data:\n",
    "| Distance         | Dimension     | Num Errors |\n",
    "|--------------|-----------|------------|\n",
    "| Hyperbolic |2     | 19     |\n",
    "| Hyperbolic      | 4  | 0     |\n",
    "| Hyperbolic      | 6  | 0     |\n",
    "| Hyperbolic      | 8  | 0     |\n",
    "| Hyperbolic      | 16  | 0     |\n",
    "| Hyperbolic      | 32  | 0     |\n",
    "| Hyperbolic      | 64  | 0     |\n",
    "| Hyperbolic      | 128  | 0     |\n",
    "\n",
    "\n",
    "Moms Data:\n",
    "| Distance         | Dimension     | Num Errors |\n",
    "|--------------|-----------|------------|\n",
    "| Hyperbolic |2     | 0     |\n",
    "| Hyperbolic      | 4  | 0     |\n",
    "| Hyperbolic      | 6  | 0     |\n",
    "| Hyperbolic      | 8  | 0     |\n",
    "| Hyperbolic      | 16  | 0     |\n",
    "| Hyperbolic      | 32  | 0     |\n",
    "| Hyperbolic      | 64  | 0     |\n",
    "| Hyperbolic      | 128  | 0     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
