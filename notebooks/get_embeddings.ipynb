{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from icecream import ic\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# local files\n",
    "from src.util.data_handling.string_generator import str_seq_to_num_seq, ALPHABETS\n",
    "from src.util.data_handling.data_loader import save_as_pickle, load_dataset\n",
    "from src.models.pair_encoder import PairEmbeddingDistance\n",
    "from src.util.distance_functions.distance_matrix import DISTANCE_MATRIX\n",
    "from src.util.ml_and_math.loss_functions import AverageMeter\n",
    "from src.util.data_handling.closest_string_dataset import ReferenceDataset, QueryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings, radius, distance_str):\n",
    "    \"\"\"Project embeddings to an hypersphere of a certain radius.\"\"\"\n",
    "    \n",
    "    min_scale = 1e-7\n",
    "    if distance_str == 'hyperbolic':\n",
    "        max_scale = 1 - 1e-3\n",
    "    else:\n",
    "        max_scale = 1e10\n",
    "\n",
    "    return F.normalize(embeddings, p=2, dim=1) * radius.clamp_min(min_scale).clamp_max(max_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ids, id_to_str_seq, alphabet_str, length, batch_size, num_seqs=None, labels=None, dataset_type='reference'):\n",
    "    \"\"\"Convert a list of greengenes otu ids to a dataloader. \"\"\"\n",
    "    \n",
    "    if num_seqs is None:\n",
    "        alphabet = ALPHABETS[alphabet_str]\n",
    "        str_seqs = [id_to_str_seq[str(_id)] for _id in ids]\n",
    "        num_seqs = [str_seq_to_num_seq(s, length=length, alphabet=alphabet) for s in tqdm(str_seqs, desc='Convert string sequences to numerical sequences')]\n",
    "    \n",
    "    if dataset_type == 'reference':\n",
    "        dataset = ReferenceDataset(num_seqs)\n",
    "    elif dataset_type == 'query':\n",
    "        dataset = QueryDataset(num_seqs, labels)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_strings(loader, model, device, radius=0, distance_str=''):\n",
    "    \"\"\" Embeds the sequences of a dataset one batch at the time given an encoder \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for sequences in tqdm(loader, desc='Embed the sequences'):\n",
    "        sequences = sequences.to(device)\n",
    "        # embedded = model.encode(sequences)\n",
    "        embedded = normalize_embeddings(model(sequences), radius, distance_str)\n",
    "        embeddings.append(embedded.cpu().detach())\n",
    "\n",
    "    embeddings = torch.cat(embeddings, axis=0)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(encoder_path):\n",
    "    \n",
    "    # model\n",
    "    model_class, model_args, state_dict, distance_str, radius, scaling = torch.load(encoder_path)\n",
    "    encoder_model = model_class(**vars(model_args))\n",
    "    \n",
    "    # Restore best model\n",
    "    print('Loading model ' + encoder_path)\n",
    "    encoder_model.load_state_dict(state_dict)\n",
    "    encoder_model.eval()\n",
    "    \n",
    "    return encoder_model, distance_str, radius, scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_embeddings(ids, auxillary_data_path, encoder_path, batch_size=128, no_cuda=False, seed=42):\n",
    "    \"\"\"Convert a list of greengenes otu ids to PyTorch embeddings.\"\"\"\n",
    "    \n",
    "    # set device\n",
    "    cuda = not no_cuda and torch.cuda.is_available()\n",
    "    device = 'cuda' if cuda else 'cpu'\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # set the random seed\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # restore best model\n",
    "    encoder_model, distance_str, radius, scaling = load_model(encoder_path)\n",
    "    \n",
    "    # turn greengene ids into dataloader of (numerical) greengene sequences\n",
    "    id_to_str_seq, _, alphabet, length = load_dataset(auxillary_data_path)\n",
    "    sequence_dataloader = get_dataloader(ids, id_to_str_seq, alphabet, length, batch_size)\n",
    "    \n",
    "    # get embeddings\n",
    "    embeddings = embed_strings(sequence_dataloader, encoder_model, device, radius=radius, distance_str=distance_str)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "padding 0\n",
      "Loading model ../models/transformer_hyperbolic_16_model.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert string sequences to numerical sequences: 100%|██████████| 300/300 [00:00<00:00, 3092.83it/s]\n",
      "Embed the sequences: 100%|██████████| 3/3 [00:00<00:00, 99.27it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder_path = '../models/transformer_hyperbolic_16_model.pickle'\n",
    "auxillary_data_path = '../data/interim/greengenes/auxillary_data.pickle'\n",
    "id_to_str_seq, split_to_ids, alphabet, length = load_dataset(auxillary_data_path)\n",
    "ids = split_to_ids['ref'][:300]\n",
    "batch_size = 128\n",
    "no_cuda = False\n",
    "seed = 42\n",
    "\n",
    "embeddings = ids_to_embeddings(ids, auxillary_data_path, encoder_path, batch_size=batch_size, no_cuda=no_cuda, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
